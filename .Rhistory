install.packages("tidyverse")
install.packages(c("tidyverse","readxl","xlsx","writexl","tidytext"))
install.packages(c("devtools","qdap","tm","stopwords"))
devtools::install_github("nurandi/katadasaR")
install.packages("stringr")
install.packages(c("devtools", "qdap", "tm", "stopwords"))
library(dplyr)
library(stringr)
library(tm)
library(stopwords)
library(katadasaR)
library(stringi)
library(qdapRegex)
library(igraph)
library(networkD3)
library(readxl)
df <- read.csv("covid19_tweet.csv")
save.image("~/KMMI_R/Tugas14/env.RData")
df1 <- df %>% select(screen_name,text)
df1$screen_name <- paste0('@',df1$screen_name)
library(tidyr)
df2 <- df1 %>%
unite(teks,screen_name,text,sep=" ")
df3 <- str_extract_all(df2$teks,"(@[[:alnum:]_]*)")
df3 <- sapply(df3,paste,collapse=" ")
df3 <- data.frame(df3)
library(tidytext)
df3$count <- str_count(df3$df3,"\\S+")
df4 <- df3 %>% filter(count > 1)
df5 <- df4 %>%
select(df3) %>%
unnest_tokens(username,df3,token = "ngrams",n=2)
df6 <- df5 %>%
separate(username,into=c("source","target"),sep=" ")
df6$source <- paste0('@',df6$source)
df6$target <- paste0('@',df6$target)
View(df6)
df14 <- filter(df,str_detect(text,"pemerintah|menteri"))
View(df14)
View(df14)
View(df)
dffilter <- filter(df,str_detect(text,"pemerintah|menteri"))
install.packages("tidyverse")
install.packages(c("tidyverse","readxl","xlsx","writexl","tidytext"))
install.packages(c("devtools","qdap","tm","stopwords"))
devtools::install_github("nurandi/katadasaR")
install.packages("stringr")
install.packages(c("devtools", "qdap", "tm", "stopwords"))
install.packages(c("devtools", "qdap", "tm", "stopwords"))
install.packages(c("devtools", "qdap", "tm", "stopwords"))
rm(df14)
df1 <- dffilter %>% select(screen_name,text)
library(dplyr)
library(tm)
library(stopwords)
library(katadasaR)
library(stringi)
library(qdapRegex)
library(igraph)
library(networkD3)
library(readxl)
View(df1)
View(df3)
View(df6)
dffilter <- filter(df,str_detect(text,"pemerintah|menteri"))
library(stringr)
dffilter <- filter(df,str_detect(text,"pemerintah|menteri"))
df1 <- dffilter %>% select(screen_name,text)
df1$screen_name <- paste0('@',df1$screen_name)
library(tidyr)
library(tidyr)
df2 <- df1 %>%
unite(teks,screen_name,text,sep=" ")
library(stringr)
df3 <- str_extract_all(df2$teks,"(@[[:alnum:]_]*)")
df3 <- sapply(df3,paste,collapse=" ")
df3 <- data.frame(df3)
df3$count <- str_count(df3$df3,"\\S+")
df4 <- df3 %>% filter(count > 1)
library(tidytext)
df5 <- df4 %>%
select(df3) %>%
unnest_tokens(username,df3,token = "ngrams",n=2)
df6 <- df5 %>%
separate(username,into=c("source","target"),sep=" ")
df6$source <- paste0('@',df6$source)
df6$target <- paste0('@',df6$target)
library(igraph)
ig <- graph_from_data_frame(df6,directed=FALSE)
write_graph(ig,"covid19.graphml",format="graphml")
save.image("~/KMMI_R/Tugas14/env.RData")
View(df6)
View(df)
View(df)
install.packages("tidyverse")
install.packages(c("tidyverse","readxl","xlsx","writexl","tidytext"))
install.packages(c("devtools","qdap","tm","stopwords"))
devtools::install_github("nurandi/katadasaR")
install.packages("stringr")
library(dplyr)
library(tm)
library(stopwords)
library(katadasaR)
library(stringi)
library(qdapRegex)
library(networkD3)
library(readxl)
old <- c(" ni "," tu "," org "," yg "," ga ","ambik"," klo "," ngga ","tdk", " nggak ", " ya ","kualalumpur","corona","pedemik")
new <- c(" ini "," itu "," orang "," yang "," tidak ","ambil"," kalau "," tidak "," tidak ", " tidak "," iya ","KualaLumpur","covid","pandemi")
hapus <- c("covid-19","vaksin","covid", "pandemi","lock down")
fungsi_proses <- function(a){
a %>%
casefold() %>%
rm_url(pattern = pastex("@rm_twitter_url","@rm_url")) %>%
gsub('#\\S+','',.) %>%
gsub('@\\S+','',.) %>%
gsub('[^[:alpha:] ]','',.) %>%
stri_trans_general("latin-ascii") %>%
stri_replace_all_fixed(old,new,vectorize_all = FALSE) %>%
removeWords(stopwords(language = "id", source = "nltk")) %>%
removeWords(hapus)
}
dfnew <- mutate(df,komentar_bersih=sapply(text,fungsi_proses))
library(stringr)
dffilter <- filter(dfnew,str_detect(text,"pemerintah|menteri"))
dffilter <- filter(df,str_detect(text,"pemerintah|menteri"))
dfnew <- mutate(dffilter,komentar_bersih=sapply(text,fungsi_proses))
View(dfnew)
library(tidytext)
dftoken <- dfnew %>%
select(komentar_bersih) %>%
unnest_tokens(kata,komentar_bersih) %>%
count(kata) %>%
top_n(30)
library(ggplot2)
ggplot(dftoken,aes(x=reorder(kata,n),y=n)) + geom_col() + coord_flip()
library(wordcloud2)
wordcloud2(dftoken,size=0.3)
ggplot(dftoken,aes(x=reorder(kata,n),y=n)) + geom_col() + coord_flip()
dftoken %>%
top_n(100,n) %>%
wordcloud2()
dftoken %>%
top_n(50,n) %>%
wordcloud2()
wordcloud2(dftoken,size=0.3)
dftoken2 %>%
top_n(15,n) %>%
ggplot(aes(x=reorder(kata,n),y=n)) + geom_col() + coord_flip()
dftoken2 %>%
top_n(15,n) %>%
ggplot(aes(x=reorder(kata,n),y=n)) + geom_col() + coord_flip()
dftoken %>%
top_n(15,n) %>%
ggplot(aes(x=reorder(kata,n),y=n)) + geom_col() + coord_flip()
dftoken %>%
top_n(25,n) %>%
ggplot(aes(x=reorder(kata,n),y=n)) + geom_col() + coord_flip()
dftoken3 %>%
top_n(100,n) %>%
wordcloud2()
dftoken %>%
top_n(100,n) %>%
wordcloud2()
df1 <- dfnew %>% select(screen_name,text)
df1$screen_name <- paste0('@',df1$screen_name)
library(tidyr)
df2 <- df1 %>%
unite(teks,screen_name,text,sep=" ")
df3 <- str_extract_all(df2$teks,"(@[[:alnum:]_]*)")
df3 <- sapply(df3,paste,collapse=" ")
df3 <- data.frame(df3)
df3$count <- str_count(df3$df3,"\\S+")
df4 <- df3 %>% filter(count > 1)
library(tidytext)
df5 <- df4 %>%
select(df3) %>%
unnest_tokens(username,df3,token = "ngrams",n=2)
df6 <- df5 %>%
separate(username,into=c("source","target"),sep=" ")
df6$source <- paste0('@',df6$source)
df6$target <- paste0('@',df6$target)
library(igraph)
ig <- graph_from_data_frame(df6,directed=FALSE)
write_graph(ig,"covid19.graphml",format="graphml")
View(dfnew)
library(ggplot2)
dftoken %>%
top_n(25,n) %>%
ggplot(aes(x=reorder(kata,n),y=n)) + geom_col() + coord_flip()
library(wordcloud2)
dftoken %>%
top_n(100,n) %>%
wordcloud2()
df1 <- dfnew %>% select(screen_name,komentar_bersih)
df1$screen_name <- paste0('@',df1$screen_name)
df1$screen_name <- paste0('@',df1$screen_name)
df2 <- df1 %>%
unite(teks,screen_name,komentar_bersih,sep=" ")
df3 <- str_extract_all(df2$teks,"(@[[:alnum:]_]*)")
df3 <- sapply(df3,paste,collapse=" ")
df3 <- data.frame(df3)
df3$count <- str_count(df3$df3,"\\S+")
df4 <- df3 %>% filter(count > 1)
df5 <- df4 %>%
select(df3) %>%
unnest_tokens(username,df3,token = "ngrams",n=2)
df6 <- df5 %>%
separate(username,into=c("source","target"),sep=" ")
df6$source <- paste0('@',df6$source)
df6$target <- paste0('@',df6$target)
ig <- graph_from_data_frame(df6,directed=FALSE)
write_graph(ig,"covid19.graphml",format="graphml")
df1 <- dfnew %>% select(screen_name,text)
df1$screen_name <- paste0('@',df1$screen_name)
df2 <- df1 %>%
unite(teks,screen_name,text,sep=" ")
df3 <- str_extract_all(df2$teks,"(@[[:alnum:]_]*)")
df3 <- sapply(df3,paste,collapse=" ")
df3 <- data.frame(df3)
df3 <- data.frame(df3)
df3$count <- str_count(df3$df3,"\\S+")
df4 <- df3 %>% filter(count > 1)
df5 <- df4 %>%
select(df3) %>%
unnest_tokens(username,df3,token = "ngrams",n=2)
df6 <- df5 %>%
separate(username,into=c("source","target"),sep=" ")
df6$source <- paste0('@',df6$source)
df6$target <- paste0('@',df6$target)
ig <- graph_from_data_frame(df6,directed=FALSE)
write_graph(ig,"covid19.graphml",format="graphml")
save.image("~/KMMI_R/Tugas14/env.RData")
library(dplyr)
library(tm)
library(stopwords)
library(katadasaR)
library(stringi)
library(qdapRegex)
library(networkD3)
library(readxl)
library(stringr)
library(tidytext)
library(ggplot2)
library(wordcloud2)
dftoken %>%
top_n(100,n) %>%
wordcloud2()
View(df)
